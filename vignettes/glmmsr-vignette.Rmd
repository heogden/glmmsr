---
title: "Fitting GLMMs with `glmmsr`"
author: "Helen Ogden"
date: " "
output: rmarkdown::html_vignette
bibliography: glmmsr.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
  
---

## Introduction

The `glmmsr` package is designed to fit generalized linear mixed
models (GLMMs) using the sequential reduction approximation to the likelihood
[@Ogden2015]. It is based on `lme4` [@lme4], but with an extended interface
to allow easy fitting of a wider range of models. At the moment, the sequential
reduction approximation is not used, and the package is only an interface to
lme4. This document explains how to use the subformula interface, demonstrated 
with some examples from the `BradleyTerry2` package [@BradleyTerry2].

## The subformula interface
The function used to fit a GLMM is `glmerSR`, which is based on `glmer` from
`lme4`. A typical call would look like
`glmerSR(formula, subformula, data, family)`
where

1. `formula` may contain one or more terms surrounded with `Sub(.)`. We call the
expression contained within `Sub(.)` a **substitution expression**. This is a 
mathematical expression dictating how the response depends on a
**substituted variable**: a dummy variable not contained in `data`. 

2. `subformula` contains a **subformula** for each substituted variable, which
describes how the substituted variable depends on 
covariates.

Next, we consider an example of the type of model we might want to fit using 
this interface.

## Pairwise competition models
Suppose that we observe the outcome of a set of matches played between pairs of 
players, and that we also observe some covariates $x_{i}$ for each player $i$. 
We suppose that each player $i$ has an 'ability' $\lambda_i$, and that
\[Pr(\text{$i$ beats $j$} | \lambda_i, \lambda_j) = g(\lambda_i - \lambda_j),\]
where $g(.)$ is an inverse link function. If we are interested in how the 
ability depends on the covariates, we might model
\[\lambda_i = \beta x_{i} + b_i, \]
where $b_i \sim N(0, \sigma^2)$, and $\beta$ and $\sigma$ are unknown
parameters.

This is a structured pairwise competition model. The `BradleyTerry2` package 
provides a good interface to fit these models, but it uses Penalized Quasi 
Likelihood (PQL) for inference if there are random effects in the model. PQL
is often a poor approximation to the true likelihood. 

We wrote down the structured pairwise competition model using a two-step 
approach: first we described how the response depends on the unknown 
abilities, then we wrote down how the abilities depend on covariates. This type 
of model can be written quite naturally using the subformula interface. We have 
a formula
`response ~ 0 + Sub(ability[player1] - ability[player2])`, 
where `ability` is a substitution variable. We write
down a corresponding subformula
`ability[i] ~ 0 + x[i] + (1 | i)`.
Here `player1` and `player2` are factors with common levels, and `x`
is a vector of player-specific covariates, where the ordering of the players is
given by the levels of `player1` and `player2`. The index `i` is arbitrary, and 
is deduced automatically from the levels of `player1` and `player2`.

## Example: `chameleons` data

@Stuart-Fox2006 study contests between male Cape dwarf chameleons.
The data are available in `BradleyTerry2`: see `?chameleons` for
more details. The model suggested by 
@Stuart-Fox2006 includes an experience effect: we allow
the ability for each chameleon to change as the tournament progresses.

In particular, for each chameleon $i$ at each match $m$, we count the 
number of wins for that chameleon in its (at most) two previous matches. 
We start by constructing a matrix `prevwins2` to record these counts.
```{r}
library(BradleyTerry2)
winner <- chameleons$winner$ID
loser <- chameleons$loser$ID
match <- 1:length(winner)

wins <- matrix(0, nrow = length(levels(winner)), ncol = length(winner))
wins[cbind(as.numeric(winner), match)] <- 1

losses <- matrix(0, nrow = length(levels(winner)), ncol = length(winner))
losses[cbind(as.numeric(loser), match)] <- 1

contests <- wins + losses

find_prev2 <- function(wins_im, contests_im) {
  m <- min(2, sum(contests_im))
  if(m > 0) {
    res <- sum(wins_im[rev(which(contests_im > 0L))[1:m]])
  } else{
    res <- 0
  }
  res
}

prevwins2 <- matrix(0, nrow = nrow(wins), ncol = ncol(wins))
for(i in 1:nrow(wins)) {
  for(m in 2:ncol(wins)) {
    prevwins2[i, m] <- find_prev2(wins[i, 1:(m-1)], contests[i, 1:(m-1)])
  }
}
```

Then we fit the model
```{r}
library(glmmsr)
resp <- rep(1, length(winner))
cham_dat <- c(list(resp = resp, winner = winner, loser = loser, 
                  match = match, prevwins2 = prevwins2), 
             as.list(chameleons$predictors))

cham_mod <- glmerSR(resp ~ 0 + Sub(ability[winner, match] -
                                   ability[loser, match]),
                    ability[i, m] ~ 0 + prevwins2[i, m] + ch.res[i] 
                                    + prop.main[i] + (1 | i),
                    family = binomial, data = cham_dat)

print(summary(cham_mod), correlation = FALSE, show.resids = FALSE)
```
We can fit the same model with `BradleyTerry2`.

```{r}
cham_mod_BTm <- BTm(player1 = winner, player2 = loser,
                    formula = ~ prev.wins.2 + ch.res[ID] + prop.main[ID] + (1|ID),
                    id = "ID", data = chameleons)
summary(cham_mod_BTm)
```
In this case the two fits are the same, because in both
cases the random effects variance is estimated to be zero.

## References
